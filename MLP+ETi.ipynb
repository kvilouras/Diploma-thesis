{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MLP+ETi.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMhm6PPuvhc/N4QRKxYCjty"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"NRoQ8wmreD32","colab_type":"code","colab":{}},"source":["#imports \n","%matplotlib inline\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import h5py\n","import pandas as pd\n","import librosa\n","import librosa.display\n","import soundfile as sf\n","\n","from IPython.display import clear_output\n","import timeit\n","import gc\n","\n","import keras\n","import tensorflow \n","\n","print(\"Librosa version = \", librosa.__version__)\n","print(\"Pysoundfile version = \", sf.__version__)\n","print(\"Keras version = \", keras.__version__)\n","print(\"Tensorflow version = \", tensorflow.__version__)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8UJOnhNvepnG","colab_type":"code","colab":{}},"source":["TrainFile = '/...your directory.../fold1_train.csv'\n","ValFile = '/...your directory/fold1_evaluate.csv'\n","\n","sr = 44100\n","SampleDuration = 10\n","\n","#log-mel spectrogram parameters\n","FreqBins = 128\n","NumFFTPoints = 2048\n","HopLength = int(NumFFTPoints/2)\n","TimeBins = int(np.ceil(SampleDuration*sr/HopLength))\n","\n","batch_size = 16\n","epochs = 100"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EtVtfMSJepqp","colab_type":"code","colab":{}},"source":["# load filenames and labels\n","\n","dev_train = pd.read_csv(TrainFile, sep='\\t', encoding='ASCII')\n","dev_val = pd.read_csv(ValFile, sep='\\t', encoding='ASCII')\n","wav_train = dev_train['filename'].tolist()\n","wav_val = dev_val['filename'].tolist()\n","y_train_labels =  dev_train['scene_label'].astype('category').cat.codes.values # dataframe to categorical\n","y_val_labels =  dev_val['scene_label'].astype('category').cat.codes.values\n","\n","ClassNames = np.unique(dev_train['scene_label']) # returns the sorted unique elements of an array\n","NumClasses = len(ClassNames)\n","\n","y_train = keras.utils.to_categorical(y_train_labels, NumClasses, dtype='float32') # Converts a class vector (integers) to binary class matrix,\n","y_val = keras.utils.to_categorical(y_val_labels, NumClasses, dtype='float32') # e.g. for use with categorical_crossentropy."],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NNp6oO7uepuL","colab_type":"code","colab":{}},"source":["# feature extraction stage + early temporal integration, training\n","\n","X_train_short = np.zeros((len(wav_train),40,TimeBins),'float32') \n","X_train = np.zeros((len(wav_train),40,5),'float32') \n","\n","start = timeit.default_timer()\n","\n","for i in range(len(wav_train)):\n","\n","    clear_output(wait=True)\n","\n","    y, fs = sf.read('...your directory...' + wav_train[i], stop=SampleDuration*sr)\n","\n","    # baseline features, short-frame format\n","    X_train_short[i,0,:] = librosa.feature.zero_crossing_rate(y, frame_length=2048, hop_length=HopLength) #zcr:np.ndarray [shape=(1, t)]\n","    X_train_short[i,1,:] = librosa.feature.spectral_centroid(y, sr=sr, n_fft=NumFFTPoints, hop_length=HopLength) #centroid:np.ndarray [shape=(1, t)]\n","    X_train_short[i,1,:] = np.log10(X_train_short[i,1,:])\n","    X_train_short[i,2,:] = librosa.feature.spectral_rolloff(y, sr=sr, n_fft=NumFFTPoints, hop_length=HopLength, roll_percent=0.85) #rolloff:np.ndarray [shape=(1, t)]\n","    X_train_short[i,2,:] = np.log10(X_train_short[i,2,:])\n","    X_train_short[i,3,:] = librosa.feature.spectral_flatness(y, n_fft=NumFFTPoints, hop_length=HopLength, power=2.0) #flatness:np.ndarray [shape=(1, t)]\n","    X_train_short[i,4,:] = librosa.feature.spectral_bandwidth(y, sr=sr, n_fft=NumFFTPoints, hop_length=HopLength, p=2) #bandwidth:np.ndarray [shape=(1, t)]\n","    X_train_short[i,4,:] = np.log10(X_train_short[i,4,:])\n","    X_train_short[i,5:12,:] = librosa.feature.spectral_contrast(y, sr=sr, n_fft=NumFFTPoints, hop_length=HopLength, fmin=200.0, n_bands=6, quantile=0.02) #contrast:np.ndarray [shape=(n_bands + 1, t)]\n","    S = librosa.feature.melspectrogram(y, sr=sr, n_fft=NumFFTPoints, hop_length=HopLength, htk=True, fmin=0.0, fmax=sr/2, norm=None, n_mels=FreqBins, power=2.0)\n","    S = np.log10(S + 1e-8)\n","    mfcc = librosa.feature.mfcc(sr=sr, S=S, n_mfcc=14) #M:np.ndarray [shape=(n_mfcc, t)\n","    X_train_short[i,12:26,:] = mfcc\n","    X_train_short[i,26:40,:] = librosa.feature.delta(mfcc, order=1, axis=-1)\n","\n","\n","    # Enhanced Temporal Integration\n","    for j in range(40):\n","\n","        X_train[i,j,0] = np.mean(X_train_short[i,j,:], axis=-1)\n","        X_train[i,j,1] = np.std(X_train_short[i,j,:], axis=-1)\n","\n","        # mean sequential difference\n","        X_train[i,j,2] = np.mean(np.absolute(X_train_short[i,j,1:431] - X_train_short[i,j,0:430]), axis=-1)\n","\n","        # mean crossing rate\n","        dm = np.multiply((X_train_short[i,j,1:431]-X_train[i,j,0]), (X_train_short[i,j,0:430]-X_train[i,j,0]))\n","        ## Indicator function\n","        for idx in range(len(dm)):\n","            if dm[idx]<0:\n","                dm[idx]+=1\n","        X_train[i,j,3] = np.mean(dm)\n","\n","        # crest factor\n","        X_train[i,j,4] = np.amax(X_train_short[i,j,:], axis=-1) / X_train[i,j,0]\n","    \n","\n","    stop = timeit.default_timer()\n","\n","    if (i/len(wav_train)*100) < 5:\n","        expected_time = \"Calculating...\"\n","\n","    else:\n","        time_perc = timeit.default_timer()\n","        expected_time = np.round( ( (time_perc-start) / (i/len(wav_train) ) /60,2))\n","\n","    print(\"Current Progress:\", np.round(i/len(wav_train)*100, 2), \"%\")\n","    print(\"Current runtime:\", np.round((stop-start)/60, 2), \"mins\")\n","    print(\"Expected runtime:\", expected_time, \"mins\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"X3AhTLzGepyS","colab_type":"code","colab":{}},"source":["X_train = np.reshape(X_train, (len(wav_train),200)) # proper input to the network"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Sp2J2IfWgz7W","colab_type":"code","colab":{}},"source":["# same for validation\n","X_val_short = np.zeros((len(wav_val),40,TimeBins),'float32') \n","X_val = np.zeros((len(wav_val),40,5),'float32') \n","\n","start = timeit.default_timer()\n","\n","for i in range(len(wav_val)):\n","\n","    clear_output(wait=True)\n","\n","    y, fs = sf.read('...your directory...' + wav_val[i], stop=SampleDuration*sr)\n","\n","    # baseline features, short-frame format\n","    X_val_short[i,0,:] = librosa.feature.zero_crossing_rate(y, frame_length=2048, hop_length=HopLength) #zcr:np.ndarray [shape=(1, t)]\n","    X_val_short[i,1,:] = librosa.feature.spectral_centroid(y, sr=sr, n_fft=NumFFTPoints, hop_length=HopLength) #centroid:np.ndarray [shape=(1, t)]\n","    X_val_short[i,1,:] = np.log10(X_val_short[i,1,:])\n","    X_val_short[i,2,:] = librosa.feature.spectral_rolloff(y, sr=sr, n_fft=NumFFTPoints, hop_length=HopLength, roll_percent=0.85) #rolloff:np.ndarray [shape=(1, t)]\n","    X_val_short[i,2,:] = np.log10(X_val_short[i,2,:])\n","    X_val_short[i,3,:] = librosa.feature.spectral_flatness(y, n_fft=NumFFTPoints, hop_length=HopLength, power=2.0) #flatness:np.ndarray [shape=(1, t)]\n","    X_val_short[i,4,:] = librosa.feature.spectral_bandwidth(y, sr=sr, n_fft=NumFFTPoints, hop_length=HopLength, p=2) #bandwidth:np.ndarray [shape=(1, t)]\n","    X_val_short[i,4,:] = np.log10(X_val_short[i,4,:])\n","    X_val_short[i,5:12,:] = librosa.feature.spectral_contrast(y, sr=sr, n_fft=NumFFTPoints, hop_length=HopLength, fmin=200.0, n_bands=6, quantile=0.02)\n","    S = librosa.feature.melspectrogram(y, sr=sr, n_fft=NumFFTPoints, hop_length=HopLength, htk=True, fmin=0.0, fmax=sr/2, norm=None, n_mels=FreqBins, power=2.0)\n","    S = np.log10(S + 1e-8)\n","    mfcc = librosa.feature.mfcc(sr=sr, S=S, n_mfcc=14) #M:np.ndarray [shape=(n_mfcc, t)\n","    X_val_short[i,12:26,:] = mfcc\n","    X_val_short[i,26:40,:] = librosa.feature.delta(mfcc, order=1, axis=-1)\n","\n","\n","    # ETi\n","    for j in range(40):\n","\n","        X_val[i,j,0] = np.mean(X_val_short[i,j,:], axis=-1)\n","        X_val[i,j,1] = np.std(X_val_short[i,j,:], axis=-1)\n","\n","        # mean sequential difference\n","        X_val[i,j,2] = np.mean(np.absolute(X_val_short[i,j,1:431] - X_val_short[i,j,0:430]), axis=-1)\n","\n","        # mean crossing rate\n","        dm = np.multiply((X_val_short[i,j,1:431]-X_val[i,j,0]), (X_val_short[i,j,0:430]-X_val[i,j,0]))\n","        ## Indicator function\n","        for idx in range(len(dm)):\n","            if dm[idx]<0:\n","                dm[idx]+=1\n","        X_val[i,j,3] = np.mean(dm)\n","\n","        # crest factor\n","        X_val[i,j,4] = np.amax(X_val_short[i,j,:], axis=-1) / X_val[i,j,0]\n","    \n","\n","    stop = timeit.default_timer()\n","\n","    if (i/len(wav_val)*100) < 5:\n","        expected_time = \"Calculating...\"\n","\n","    else:\n","        time_perc = timeit.default_timer()\n","        expected_time = np.round( ( (time_perc-start) / (i/len(wav_val) ) /60,2))\n","\n","    print(\"Current Progress:\", np.round(i/len(wav_val)*100, 2), \"%\")\n","    print(\"Current runtime:\", np.round((stop-start)/60, 2), \"mins\")\n","    print(\"Expected runtime:\", expected_time, \"mins\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"laMtQBWBgz_q","colab_type":"code","colab":{}},"source":["X_val = np.reshape(X_val, (len(wav_val),200))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jpjGwMZug0Fa","colab_type":"code","colab":{}},"source":["# MLP architecture\n","from keras.models import Model \n","from keras.layers import Dense, Dropout, Input, BatchNormalization\n","from keras.initializers import he_uniform, he_normal, lecun_uniform, lecun_normal, glorot_uniform, glorot_normal\n","from keras.regularizers import l2, l1_l2, l1\n","from keras.optimizers import Adam, SGD\n","from keras.utils import plot_model\n","\n","input1 = Input(batch_shape=(None,200)) \n","a = BatchNormalization()(input1)\n","\n","a = Dense(units=60, activation='relu', kernel_initializer=glorot_normal(seed=42), kernel_regularizer=l1_l2(0.0002))(a) \n","a = Dense(units=40, activation='relu', kernel_initializer=glorot_normal(seed=42), kernel_regularizer=l1_l2(0.0002))(a) \n","\n","out = Dense(units=10, activation='softmax', kernel_initializer=glorot_normal(seed=42))(a)\n","\n","model = Model(inputs=input1, outputs=out)\n","model.compile(loss='categorical_crossentropy',\n","              optimizer = SGD(learning_rate=0.001, momentum=0.9, nesterov=True),  \n","              metrics=['accuracy'])\n","\n","model.summary()\n","# plot graph\n","plot_model(model, to_file='MLP_ETi.png')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"M7zYUSrvg0Mr","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","import datetime, os\n","\n","# Load the TensorBoard notebook extension\n","%load_ext tensorboard"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PhcbdBAyibQd","colab_type":"code","colab":{}},"source":["from keras.callbacks import TensorBoard\n","\n","logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n","tens = TensorBoard(logdir, histogram_freq=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tu--5yJEiboy","colab_type":"code","colab":{}},"source":["%tensorboard --logdir logs"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4GHhoioKibtp","colab_type":"code","colab":{}},"source":["from keras.callbacks import ModelCheckpoint, EarlyStopping\n","\n","checkpoint = ModelCheckpoint(filepath=\"weights.mlpbestacc.hdf5\", monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n","es = EarlyStopping(monitor='val_loss', patience=30)\n","\n","\n","history = model.fit(x=X_train, \n","                    y=y_train,\n","                    epochs=epochs,\n","                    verbose=2,\n","                    validation_data=(X_val, y_val), \n","                    batch_size=batch_size,\n","                    callbacks=[checkpoint, es, tens],  \n","                    )"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rWXEK0W1ibzZ","colab_type":"code","colab":{}},"source":["model.load_weights('weights.mlpbestacc.hdf5')\n","model.save('DCASE_MLP_development.h5')"],"execution_count":0,"outputs":[]}]}